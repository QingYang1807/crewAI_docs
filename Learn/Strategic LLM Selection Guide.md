# LLM战略选择指南

> 为CrewAI AI Agent选择合适LLM并编写有效任务和Agent定义的战略框架

## CrewAI的LLM选择方法

我们不提供具体的模型推荐，而是倡导一个**思维框架**，帮助您根据特定用例、限制条件和需求做出明智决策。

LLM领域发展迅速，新模型定期出现，现有模型频繁更新。最重要的是建立一个系统化的评估方法，无论使用哪些具体模型，这种方法都能保持相关性。

本指南专注于战略思维而非具体模型推荐，因为LLM领域发展迅速。

## 快速决策框架

1、分析您的任务
首先深入了解您的**任务实际需求**。考虑所涉及的**认知复杂性**、**所需的推理深度**、**预期输出的格式**以及**模型需要处理的上下文量**。这一基础分析将指导后续每个决策。

2、映射模型能力
了解需求后，将其与模型优势相匹配。不同模型家族在不同类型工作中表现出色；一些模型针对推理和分析进行了优化，另一些针对创造力和内容生成，还有一些则专注于**速度**和**效率**。

3、考虑限制条件
考虑您的实际运营限制，包括**预算限制**、**延迟要求**、**数据隐私需求**和**基础设施能力**。理论上最佳的模型在您的情况下可能不是实际最佳选择。

4、测试与迭代
从**可靠**、**易于理解**的模型开始，根据您特定用例中的实际性能进行优化。实际结果往往与理论基准不同，因此实证测试至关重要。


## 核心选择框架

### a. 任务优先思维

LLM选择最关键的步骤是了解您的任务实际需求。团队经常根据一般声誉或基准分数选择模型，而未仔细分析其具体需求。这种方法导致要么用昂贵、复杂的模型过度设计简单任务，要么用缺乏必要能力的模型来支持复杂工作。

1、推理复杂性
* **简单任务**代表日常AI工作的大部分，包括基本指令遵循、简单数据处理和简单格式操作。这些任务通常有明确的输入和输出，模糊性最小。认知负荷低，模型主要需要遵循明确指令，而非进行复杂推理。

* **复杂任务**需要多步推理、战略思考和处理模糊或不完整信息的能力。这可能涉及分析多个数据源、制定全面策略或解决需要分解成较小组件的问题。模型需要在多个推理步骤中保持上下文，并经常必须做出未明确陈述的推断。

* **创意任务**需要一种不同的认知能力，专注于生成新颖、引人入胜且符合语境的内容。这包括讲故事、营销文案创作和创造性问题解决。模型需要理解细微差别、语调和受众，同时产生感觉真实且引人入胜而非公式化的内容。

2、输出需求
* **结构化数据**任务需要格式遵循的精确性和一致性。当处理JSON、XML或数据库格式时，模型必须可靠地产生语法正确的输出，以便程序化处理。这些任务通常有严格的验证要求，对格式错误的容忍度低，使可靠性比创造性更重要。

* **创意内容**输出需要在技术能力和创意才华之间取得平衡。模型需要理解受众、语调和品牌声音，同时产生能吸引读者并实现特定沟通目标的内容。这里的质量通常是主观的，需要能够适应不同语境和目的的写作风格的模型。

* **技术内容**介于结构化数据和创意内容之间，需要精确性和清晰度。文档、代码生成和技术分析需要准确全面，同时保持对目标受众的可访问性。模型必须理解复杂的技术概念并有效沟通。

3、上下文需求
* **短上下文**情景涉及专注、直接的任务，模型需要快速处理有限信息。这些通常是事务性交互，其中速度和效率比深入理解更重要。模型不需要保持广泛的对话历史或处理大型文档。

* **长上下文**需求在处理大量文档、扩展对话或复杂多部分任务时出现。模型需要在数千个token中保持连贯性，同时准确引用早期信息。这种能力对文档分析、全面研究和复杂对话系统至关重要。

* **极长上下文**情景突破了当前可能性的界限，涉及大规模文档处理、广泛研究综合或复杂多会话交互。这些用例需要专门设计用于扩展上下文处理的模型，并通常涉及上下文长度和处理速度之间的权衡。


### b. 模型能力映射

理解模型能力需要超越营销宣传和基准分数，了解不同模型架构和训练方法的基本优势和局限性。

**1、推理模型**

推理模型代表一个专门类别，专为复杂、多步思维任务设计。当问题需要仔细分析、战略规划或系统性问题分解时，这些模型表现出色。它们通常采用思维链推理或思维树处理等技术，逐步解决复杂问题。

推理模型的优势在于它们能够在扩展推理链上保持逻辑一致性，并将复杂问题分解为可管理的组件。它们对战略规划、复杂分析以及推理质量比响应速度更重要的情况特别有价值。

然而，推理模型在速度和成本方面通常存在权衡。它们也可能不太适合创意任务或简单操作，因为它们复杂的推理能力并不需要。当您的任务涉及从系统化、逐步分析中受益的真正复杂性时，考虑这些模型。

**2、通用模型**

通用模型提供了最平衡的LLM选择方法，在各种任务中提供可靠性能，而不在任何特定领域极端专业化。这些模型在多样化数据集上训练，优化的是多功能性而非特定领域的峰值性能。

通用模型的主要优势是它们在不同类型工作中的可靠性和可预测性。它们能够胜任大多数标准业务任务，从研究和分析到内容创建和数据处理。这使它们成为需要在多样化工作流程中保持一致性能的团队的绝佳选择。

虽然通用模型在特定领域可能无法达到专业替代方案的峰值性能，但它们提供了模型管理的操作简便性和降低的复杂性。它们通常是新项目的最佳起点，让团队在可能用更专业模型优化之前了解其特定需求。


**3、快速高效模型**

快速高效模型优先考虑速度、成本效益和资源效率，而非复杂的推理能力。这些模型针对高吞吐量场景优化，其中快速响应和低运营成本比细微理解或复杂推理更重要。

这些模型在涉及常规操作、简单数据处理、函数调用和高容量任务（其中认知要求相对直接）的场景中表现出色。它们对需要快速处理许多请求或在严格预算约束内操作的应用特别有价值。

高效模型的关键考虑是确保其能力与您的任务要求一致。虽然它们可以有效处理许多常规操作，但可能难以需要细微理解、复杂推理或复杂内容生成的任务。它们最适合用于速度和成本比复杂性更重要的明确定义的常规操作。

**4、创意模型**

创意模型专门优化内容生成、写作质量和创意思维任务。这些模型通常在理解细微差别、语调和风格方面表现出色，同时产生引人入胜、符合语境且感觉自然真实的内容。

创意模型的优势在于它们能够将写作风格适应不同受众，保持一致的声音和语调，并产生有效吸引读者的内容。它们在讲故事、营销文案、品牌传播和其他以创造力和参与度为主要目标的内容任务中表现更好。

选择创意模型时，不仅要考虑它们生成文本的能力，还要考虑它们对受众、语境和目的的理解。最好的创意模型能够使其输出匹配特定的品牌声音，针对不同的受众群体，并在扩展内容中保持一致性。

**5、开源模型**

开源模型在成本控制、定制潜力、数据隐私和部署灵活性方面提供独特优势。这些模型可以在本地或私有基础设施上运行，为数据处理和模型行为提供完全控制。

开源模型的主要好处包括消除每token成本、能够针对特定用例进行微调、完全的数据隐私以及独立于外部API提供商。它们对有严格数据隐私要求、预算限制或特定定制需求的组织特别有价值。

然而，开源模型需要更多技术专长来有效部署和维护。团队需要考虑基础设施成本、模型管理复杂性以及保持模型更新和优化所需的持续努力。当计入技术开销时，总拥有成本可能高于基于云的替代方案。

## 战略配置模式

### a. 多模型方法

> 在同一团队中为不同目的使用不同模型，以优化性能和成本。

最复杂的CrewAI实现通常策略性地使用多个模型，根据Agent的特定角色和要求将不同模型分配给不同Agent。这种方法允许团队通过为每类型工作使用最合适的模型来优化性能和成本。

规划Agent受益于能够处理复杂战略思考和多步分析的推理模型。这些Agent通常作为操作的"大脑"，制定策略并协调其他Agent的工作。另一方面，内容Agent在使用擅长写作质量和受众参与的创意模型时表现最佳。处理常规操作的处理Agent可以使用优先考虑速度和成本效益的高效模型。

**示例：研究与分析团队**

```python
from crewai import Agent, Task, Crew, LLM

# 用于战略规划的高能力推理模型
manager_llm = LLM(model="gemini-2.5-flash-preview-05-20", temperature=0.1)

# 用于内容生成的创意模型
content_llm = LLM(model="claude-3-5-sonnet-20241022", temperature=0.7)

# 用于数据处理的高效模型
processing_llm = LLM(model="gpt-4o-mini", temperature=0)

research_manager = Agent(
    role="Research Strategy Manager",
    goal="Develop comprehensive research strategies and coordinate team efforts",
    backstory="Expert research strategist with deep analytical capabilities",
    llm=manager_llm,  # 用于复杂推理的高能力模型
    verbose=True
)

content_writer = Agent(
    role="Research Content Writer",
    goal="Transform research findings into compelling, well-structured reports",
    backstory="Skilled writer who excels at making complex topics accessible",
    llm=content_llm,  # 用于引人入胜内容的创意模型
    verbose=True
)

data_processor = Agent(
    role="Data Analysis Specialist",
    goal="Extract and organize key data points from research sources",
    backstory="Detail-oriented analyst focused on accuracy and efficiency",
    llm=processing_llm,  # 用于常规任务的快速、经济高效模型
    verbose=True
)

crew = Crew(
    agents=[research_manager, content_writer, data_processor],
    tasks=[...],  # 您的具体任务
    manager_llm=manager_llm,  # 管理器使用推理模型
    verbose=True
)
```

成功实施多模型方法的关键是理解不同Agent如何互动，并确保模型能力与Agent职责保持一致。这需要仔细规划，但可以在输出质量和运营效率方面带来显著改进。

### b. 组件特定选择

**1、管理器LLM**

管理器LLM在分层CrewAI流程中扮演关键角色，作为多个Agent和任务的协调点。该模型需要在委派、任务优先级排序和维护多个并发操作的上下文方面表现出色。

有效的管理器LLM需要强大的推理能力以做出良好的委派决策，一致的性能以确保可预测的协调，以及出色的上下文管理以同时跟踪多个Agent的状态。模型需要理解不同Agent的能力和限制，同时优化任务分配以提高效率和质量。

成本考虑对管理器LLM特别重要，因为它们参与每个操作。模型需要提供足够的能力以进行有效协调，同时对频繁使用保持成本效益。这通常意味着找到提供良好推理能力而不需要最复杂选项溢价价格的模型。


**2、函数调用LLM**

函数调用LLM处理所有Agent的工具使用，使其对严重依赖外部工具和API的团队至关重要。这些模型需要擅长理解工具能力，准确提取参数，并有效处理工具响应。

函数调用LLM最重要的特性是精确性和可靠性，而非创造性或复杂的推理。模型需要始终从自然语言请求中提取正确的参数，并适当处理工具响应。速度也很重要，因为工具使用通常涉及可能影响整体性能的多次往返。

许多团队发现，专业的函数调用模型或具有强大工具支持的通用模型比创意或推理专注的模型更适合这一角色。关键是确保模型能够可靠地弥合自然语言指令和结构化工具调用之间的差距。

**3、Agent特定覆盖**

个别Agent可以覆盖团队级LLM设置，当它们的特定需求与一般团队要求显著不同时。这种能力允许进行微调优化，同时保持大多数Agent的操作简便性。

当Agent角色需要与其他团队成员显著不同的能力时，考虑Agent特定覆盖。例如，创意写作Agent可能受益于针对内容生成优化的模型，而数据分析Agent可能在使用推理专注的模型时表现更好。

Agent特定覆盖的挑战是在优化和操作复杂性之间取得平衡。每个额外模型都会增加部署、监控和成本管理的复杂性。团队应将覆盖重点放在性能改进证明额外复杂性是合理的Agent上。


## 任务定义框架

### a. 注重清晰度而非复杂性

有效的任务定义在确定CrewAI输出质量方面通常比模型选择更重要。定义良好的任务提供清晰的方向和上下文，使即使是普通模型也能表现良好，而定义不佳的任务可能导致即使是复杂的模型也产生不满意的结果。

**1、有效的任务描述**

最好的任务描述在提供足够细节和保持清晰度之间取得平衡。它们应该明确定义具体目标，使成功标准没有模糊性，同时解释方法或方法论，使Agent理解如何进行。

有效的任务描述包括帮助Agent理解更广泛目的和需要工作限制的相关上下文和约束。它们将复杂工作分解为可以系统执行的专注步骤，而不是呈现难以系统处理的压倒性、多方面的目标。

常见错误包括目标过于模糊、未能提供必要上下文、设置不明确成功标准，或将多个无关任务合并到单个描述中。目标是为Agent提供足够的信息以成功，同时保持对单一清晰目标的专注。

**2、预期输出指南**

预期输出指南作为任务定义和Agent之间的契约，明确规定交付成果应该是什么样子以及如何评估。这些指南应该描述所需的格式和结构，以及输出被认为是完整必须包含的关键元素。

最好的输出指南提供质量指标的具体示例，明确定义完成标准，使Agent和人类评估者都能评估任务是否成功完成。这减少了模糊性，有助于确保多次任务执行的一致结果。

3、避免可应用于任何任务的通用输出描述，缺少让Agent猜测结构的格式规范，使评估困难的不明确质量标准，或未能提供帮助Agent理解期望的示例或模板。

### b. 任务排序策略

**1、顺序依赖**

当任务基于先前输出构建，信息从一个任务流向另一个任务，或质量取决于前提工作的完成时，顺序任务依赖是必不可少的。这种方法确保每个任务都有成功所需的信息和上下文。

有效实施顺序依赖需要使用上下文参数链接相关任务，通过任务进展逐步建立复杂性，并确保每个任务产生的输出作为后续任务的有意义输入。目标是在依赖任务之间保持逻辑流动，同时避免不必要的瓶颈。

当从一个任务到另一个任务有明确的逻辑进展，并且一个任务的输出真正提高后续任务的质量或可行性时，顺序依赖效果最佳。但是，如果管理不当，它们可能造成瓶颈，因此确定哪些依赖是真正必要的，而哪些只是便利的很重要。

**2、并行执行**

当任务彼此独立、时间效率重要或涉及不需要协调的不同专业领域时，并行执行变得有价值。这种方法可以显著减少总体执行时间，同时允许专业Agent同时在各自的优势领域工作。

成功的并行执行需要识别可以真正独立运行的任务，有效分组相关但独立的工作流，并在并行任务需要组合成最终交付成果时规划结果整合。关键是确保并行任务不会产生降低整体质量的冲突或冗余。

当您有多个独立研究流、不相互依赖的不同类型分析，或可以同时开发的内容创建任务时，考虑并行执行。但是，要注意资源分配，确保并行执行不会耗尽您可用的模型容量或预算。

## 为LLM性能优化Agent配置

### a. 角色驱动的LLM选择

> 通用Agent角色使选择正确的LLM变得不可能。特定角色实现针对性的模型优化。

Agent角色的特异性直接决定了哪些LLM能力对最佳性能最重要。这创造了将精确模型优势与Agent责任相匹配的战略机会。

**通用与特定角色对LLM选择的影响：**

定义角色时，考虑Agent将处理的任务最有价值的特定领域知识、工作风格和决策框架。角色定义越具体和上下文化，模型就能越有效地体现该角色。

```python
# ✅ 特定角色 - 清晰的LLM要求
specific_agent = Agent(
    role="SaaS Revenue Operations Analyst",  # 需要明确的领域专业知识
    goal="Analyze recurring revenue metrics and identify growth opportunities",
    backstory="Specialist in SaaS business models with deep understanding of ARR, churn, and expansion revenue",
    llm=LLM(model="gpt-4o")  # 为复杂分析选择推理模型
)
```

**角色到模型映射策略：**

* **"Research Analyst"** → 推理模型（GPT-4o、Claude Sonnet）用于复杂分析
* **"Content Editor"** → 创意模型（Claude、GPT-4o）用于写作质量
* **"Data Processor"** → 高效模型（GPT-4o-mini、Gemini Flash）用于结构化任务
* **"API Coordinator"** → 函数调用优化模型（GPT-4o、Claude）用于工具使用

### b. 背景故事作为模型上下文放大器

> 战略性背景故事通过提供通用提示无法实现的领域特定上下文，增强您选择的LLM的有效性。

精心制作的背景故事将您的LLM选择从通用能力转变为专业知识。这对成本优化特别重要 - 一个上下文良好的高效模型可以在没有适当上下文的情况下超越高级模型。

**上下文驱动的性能示例：**

```python
# 上下文增强模型有效性
domain_expert = Agent(
    role="B2B SaaS Marketing Strategist",
    goal="Develop comprehensive go-to-market strategies for enterprise software",
    backstory="""
    You have 10+ years of experience scaling B2B SaaS companies from Series A to IPO.
    You understand the nuances of enterprise sales cycles, the importance of product-market
    fit in different verticals, and how to balance growth metrics with unit economics.
    You've worked with companies like Salesforce, HubSpot, and emerging unicorns, giving
    you perspective on both established and disruptive go-to-market strategies.
    """,
    llm=LLM(model="claude-3-5-sonnet", temperature=0.3)  # 平衡创造力和领域知识
)

# 这个上下文使Claude能够像领域专家一样表现
# 没有它，即使是它也会产生通用的营销建议
```

**增强LLM性能的背景故事元素：**

* **领域经验**："在企业SaaS销售方面拥有10+年经验"
* **特定专业知识**："专精于B+轮技术尽职调查"
* **工作风格**："倾向于数据驱动决策和清晰文档"
* **质量标准**："坚持引用来源并展示分析工作"

### c. 整体Agent-LLM优化

最有效的Agent配置在角色特异性、背景故事深度和LLM选择之间创造协同作用。每个元素相互强化，最大化模型性能。

**优化框架：**

```python
# 示例：技术文档Agent
tech_writer = Agent(
    role="API Documentation Specialist",  # 清晰LLM要求的特定角色
    goal="Create comprehensive, developer-friendly API documentation",
    backstory="""
    You're a technical writer with 8+ years documenting REST APIs, GraphQL endpoints,
    and SDK integration guides. You've worked with developer tools companies and
    understand what developers need: clear examples, comprehensive error handling,
    and practical use cases. You prioritize accuracy and usability over marketing fluff.
    """,
    llm=LLM(
        model="claude-3-5-sonnet",  # 擅长技术写作
        temperature=0.1  # 低温度确保准确性
    ),
    tools=[code_analyzer_tool, api_scanner_tool],
    verbose=True
)
```

**一致性检查清单：**

* ✅ **角色特异性**：明确的领域和责任
* ✅ **LLM匹配**：模型优势与角色要求一致
* ✅ **背景故事深度**：提供LLM可以利用的领域上下文
* ✅ **工具集成**：工具支持Agent的专业功能
* ✅ **参数调整**：温度和设置优化角色需求

关键在于创建每个配置选择都强化LLM选择策略的Agent，在优化成本的同时最大化性能。

## 实际实施检查清单

而不是重复战略框架，以下是在CrewAI中实施LLM选择决策的战术检查清单：

**1、审计您当前的设置**

**审查内容：**

* 是否所有Agent默认使用相同的LLM？
* 哪些Agent处理最复杂的推理任务？
* 哪些Agent主要做数据处理或格式化？
* 是否有Agent严重依赖工具？

**行动**：记录当前Agent角色并识别优化机会。

**2、实施团队级策略**

**设置基线：**

```python
# 从可靠的团队默认开始
default_crew_llm = LLM(model="gpt-4o-mini")  # 成本效益基线

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

**行动**：在优化个别Agent之前，建立团队的默认LLM。

**3、优化高影响Agent**

**识别并升级关键Agent：**

```python
# 管理器或协调Agent
manager_agent = Agent(
    role="Project Manager",
    llm=LLM(model="gemini-2.5-flash-preview-05-20"),  # 高级用于协调
    # ... 其余配置
)

# 创意或面向客户的Agent
content_agent = Agent(
    role="Content Creator",
    llm=LLM(model="claude-3-5-sonnet"),  # 最擅长写作
    # ... 其余配置
)
```

**行动**：升级处理80%复杂性的20%Agent。

**4、通过企业测试验证**

**一旦将Agent部署到生产环境：**

* 使用[CrewAI AMP平台](https://app.crewai.com)对模型选择进行A/B测试
* 使用真实输入运行多次迭代以测量一致性和性能
* 比较优化设置的成本与性能
* 与团队分享结果以进行协作决策

**行动**：使用测试平台用数据驱动验证替代猜测工作。

### 何时使用不同模型类型

**1、推理模型**

当任务需要真正的多步逻辑思考、战略规划或从系统分析中受益的高级决策时，推理模型变得必不可少。这些模型在问题需要分解为组件并系统分析而非通过模式匹配或简单指令遵循处理时表现出色。

考虑将推理模型用于业务战略开发、需要从多个来源得出见解的复杂数据分析、每步依赖先前分析的多步问题解决，以及需要考虑多个变量及其互动的战略规划任务。

然而，推理模型通常成本更高且响应时间更慢，因此最好保留给其复杂能力提供真正价值的任务，而不是用于不需要复杂推理的简单操作。

**2、创意模型**

当内容生成是主要输出且该内容的质量、风格和参与度直接影响成功时，创意模型变得有价值。这些模型在写作质量和风格显著重要、需要创意构思或头脑风暴，或品牌声音和语调是重要考虑因素时表现出色。

将创意模型用于博客文章写作和文章创建、需要吸引和说服的营销文案、创意讲故事和叙事发展，以及声音和语调至关重要的品牌传播。这些模型通常比通用替代方案更好地理解细微差别和上下文。

创意模型可能不太适合精确性和事实准确性比参与度和风格更重要的技术或分析任务。它们最好在输出的创意和沟通方面是主要成功因素时使用。

**3、高效模型**

高效模型是高频率、常规操作的理想选择，其中速度和成本优化是优先事项。这些模型在任务具有清晰、明确定义的参数且不需要复杂推理或创意能力时效果最佳。

考虑将高效模型用于数据处理和转换任务、简单格式化和组织操作、精度比复杂性更重要的函数调用和工具使用，以及每操作成本是重要因素的高容量操作。

高效模型的关键是确保其能力与任务要求一致。它们可以有效处理许多常规操作，但可能难以需要细微理解、复杂推理或复杂内容生成的任务。

**4、开源模型**

当预算限制显著、存在数据隐私要求、定制需求重要或因运营或合规原因需要本地部署时，开源模型变得有吸引力。

考虑将开源模型用于数据隐私至上的内部公司工具、不能使用外部API的隐私敏感应用、每token定价过高的成本优化部署，以及需要自定义模型修改或微调的情况。

然而，开源模型需要更多技术专长来有效部署和维护。评估开源选项时，考虑包括基础设施、技术开销和持续维护在内的总拥有成本。

## 常见CrewAI模型选择陷阱

**1、'一个模型适合所有'陷阱**

**问题**：为团队中的所有Agent使用相同的LLM，不管它们的特定角色和责任。这通常是默认方法，但很少是最佳的。

**真实示例**：对战略规划经理和数据提取Agent都使用GPT-4o。经理需要值得高级成本的推理能力，但数据提取器可以用GPT-4o-mini以一小部分价格表现同样好。

**CrewAI解决方案**：利用Agent特定LLM配置将模型能力与Agent角色相匹配：

```python
# 战略Agent获得高级模型
manager = Agent(role="Strategy Manager", llm=LLM(model="gpt-4o"))

# 处理Agent获得高效模型
processor = Agent(role="Data Processor", llm=LLM(model="gpt-4o-mini"))
```

**2、忽略团队级与Agent级LLM层次结构**

**问题**：不理解CrewAI的LLM层次结构如何工作 - 团队LLM、管理器LLM和AgentLLM设置可能冲突或协调不当。

**真实示例**：将团队设置为使用Claude，但Agent配置了GPT模型，创建不一致的行为和不必要的模型切换开销。

**CrewAI解决方案**：策略性地规划LLM层次结构：

```python
crew = Crew(
    agents=[agent1, agent2],
    tasks=[task1, task2],
    manager_llm=LLM(model="gpt-4o"),  # 用于团队协调
    process=Process.hierarchical  # 使用manager_llm时
)

# Agent继承团队LLM，除非特别覆盖
agent1 = Agent(llm=LLM(model="claude-3-5-sonnet"))  # 为特定需求覆盖
```

**3、函数调用模型不匹配**

**问题**：基于通用能力选择模型，同时忽视工具繁重CrewAI工作流的函数调用性能。

**真实示例**：为主要需要调用API、搜索工具或处理结构化数据的Agent选择创意专注模型。Agent在工具参数提取和可靠函数调用方面遇到困难。

**CrewAI解决方案**：为工具繁重Agent优先考虑函数调用能力：

```python
# 对于使用许多工具的Agent
tool_agent = Agent(
    role="API Integration Specialist",
    tools=[search_tool, api_tool, data_tool],
    llm=LLM(model="gpt-4o"),  # 优秀的函数调用
    # 或者
    llm=LLM(model="claude-3-5-sonnet")  # 在工具方面也很强
)
```

**4、未经测试的过早优化**

**问题**：基于理论性能做出复杂的模型选择决策，而未用实际CrewAI工作流和任务验证。

**真实示例**：实施基于任务类型的复杂模型切换逻辑，而未测试性能改进是否证明操作复杂性是合理的。

**CrewAI解决方案**：从简单开始，然后基于真实性能数据优化：

```python
# 从这个开始
crew = Crew(agents=[...], tasks=[...], llm=LLM(model="gpt-4o-mini"))

# 测试性能，然后根据需要优化特定Agent
# 使用企业平台测试验证改进
```

**5、忽视上下文和内存限制**

**问题**：不考虑模型上下文窗口如何与CrewAI的内存和Agent间上下文共享互动。

**真实示例**：对需要在多次任务迭代中保持对话历史或在具有广泛Agent间通信的团队中使用短上下文模型。

**CrewAI解决方案**：将上下文能力与团队通信模式相匹配。

## 测试与迭代策略

**1、从简单开始**

从可靠、通用的、易于理解且广泛支持的模型开始。这为在优化特定需求之前理解您的特定要求和性能预期提供了稳定基础。

**2、测量重要事项**

制定与您的特定用例和业务需求一致的指标，而不是仅仅依赖通用基准。专注于测量直接影响您成功的成果，而非理论性能指标。

**3、基于结果迭代**

基于在您特定环境中观察到的性能进行模型更改，而不是理论考虑或一般建议。实际性能通常与基准结果或一般声誉显著不同。

**4、考虑总成本**

评估包括模型成本、开发时间、维护开销和操作复杂性在内的完全拥有成本。每token最便宜的模型在考虑所有因素时可能不是最具成本效益的选择。

> 首先专注于了解您的需求，然后选择最能匹配那些需求的模型。最好的LLM选择是在您的运营约束内持续提供您所需结果的选择。

### 企业级模型验证

对于认真优化LLM选择的团队，**CrewAI AMP平台**提供超越基本CLI测试的复杂测试能力。该平台支持全面模型评估，帮助您就LLM策略做出数据驱动的决策。

<Frame>
    <img src="https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=08580e93186b6563adca8b75da805805" alt="Enterprise Testing Interface" data-og-width="2238" width="2238" data-og-height="1700" height="1700" data-path="images/enterprise/enterprise-testing.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=280&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=d7ced6158ec4dd0b5a9928edcfc4a38d 280w, https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=560&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=0bf0f3d7110c1ac4ae4139a80e28b9c2 560w, https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=840&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=27a38bf115431233bfb9849629dc125e 840w, https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=1100&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=5d73aad5c4af3e62a82044f80add8ac1 1100w, https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=1650&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=a91a7198392462683371a28e799943a0 1650w, https://mintcdn.com/crewai/5SZbe87tsCWZY09V/images/enterprise/enterprise-testing.png?w=2500&fit=max&auto=format&n=5SZbe87tsCWZY09V&q=85&s=78aaf8869525c5633d5f06655cc46c5e 2500w" />
</Frame>

**高级测试功能：**

* **多模型比较**：同时在相同任务和输入上测试多个LLM。在并行中比较GPT-4o、Claude、Llama、Groq、Cerebras和其他领先模型的性能，以识别最适合您特定用例的模型。

* **统计严谨性**：配置具有一致输入的多次迭代以测量可靠性和性能差异。这有助于识别不仅表现好而且在多次运行中保持一致的模型。

* **真实世界验证**：使用您的实际团队输入和场景而非合成基准。该平台允许您用您的特定行业背景、公司信息和真实用例进行测试，以获得更准确的评估。

* **全面分析**：访问所有测试模型的详细性能指标、执行时间和成本分析。这实现了数据驱动的决策制定，而不是依赖一般模型声誉或理论能力。

* **团队协作**：在团队中共享测试结果和模型性能数据，实现协作决策和跨项目一致的模型选择策略。

访问[app.crewai.com](https://app.crewai.com)开始！


> 企业平台将模型选择从猜测转变为数据驱动的过程，使您能够用实际用例和要求验证本指南中的原则。

## 关键原则总结

<CardGroup cols={2}>

**1、任务驱动选择**

根据任务实际需求选择模型，而非理论能力或一般声誉。

**2、能力匹配**

将模型优势与Agent角色和责任相匹配以获得最佳性能。

**3、战略一致性**

在相关组件和工作流程中保持一致的模型选择策略。

**4、实践测试**

通过真实世界使用而非仅基准测试验证选择。

**5、迭代改进**

从简单开始，基于实际性能和需求进行优化。

**6、操作平衡**

平衡性能要求与成本和复杂性约束。


> 记住：最好的LLM选择是在您的运营约束内持续提供您所需结果的选择。首先专注于了解您的需求，然后选择最能匹配那些需求的模型。

## 当前模型格局（2025年6月）

> **时间快照**：以下模型排名代表截至2025年6月的当前排行榜地位，汇编自[LMSys Arena](https://arena.lmsys.org/)、[Artificial Analysis](https://artificialanalysis.ai/)和其他领先基准。LLM性能、可用性和价格变化迅速。始终使用您的特定用例和数据进行自己的评估。

### 按类别划分的领先模型

下表显示了不同类别当前顶级模型的代表性样本，并提供了它们在CrewAIAgent中适用性的指导：

> 这些表/指标展示了每个类别中选定的领先模型，并非详尽无遗。除了此处列出的之外，还存在许多优秀模型。目标是说明要寻找的能力类型，而非提供完整目录。

**1、推理与规划**

**最适合管理器LLM和复杂分析**

| 模型                      | 智能得分 | 成本（美元/M token） | 速度    | CrewAI最佳用途                                |
| :------------------------- | :------- | :------------------ | :------ | :-------------------------------------------- |
| **o3**                     | 70       | \$17.50             | 快速    | 复杂多Agent协调的管理器LLM                     |
| **Gemini 2.5 Pro**         | 69       | \$3.44              | 快速    | 战略规划Agent，研究协调                        |
| **DeepSeek R1**            | 68       | \$0.96              | 中等    | 预算敏感团队的性价比推理                     |
| **Claude 4 Sonnet**        | 53       | \$6.00              | 快速    | 需要细微理解的分析Agent                        |
| **Qwen3 235B (推理)**      | 62       | \$2.63              | 中等    | 推理任务的开源替代方案                        |

这些模型在多步推理方面表现出色，非常适合需要制定策略、协调其他Agent或分析复杂信息的Agent。

**2、编码与技术**

**最适合开发和工具繁重工作流**

| 模型                 | 编码性能 | 工具使用得分 | 成本（美元/M token） | CrewAI最佳用途                          |
| :-------------------- | :------- | :----------- | :------------------ | :-------------------------------------- |
| **Claude 4 Sonnet**   | 优秀     | 72.7%        | \$6.00              | 主要编码Agent，技术文档                  |
| **Claude 4 Opus**     | 优秀     | 72.5%        | \$30.00             | 复杂软件架构，代码审查                  |
| **DeepSeek V3**       | 很好     | 高           | \$0.48              | 常规开发的成本效益编码                  |
| **Qwen2.5 Coder 32B** | 很好     | 中等         | \$0.15              | 预算友好的编码Agent                      |
| **Llama 3.1 405B**    | 好       | 81.1%        | \$3.50              | 工具繁重工作流的函数调用LLM            |

这些模型针对代码生成、调试和技术问题解决进行了优化，使其成为面向开发团队的理想选择。

**3、速度与效率**

**最适合高吞吐量和实时应用**

| 模型                   | 
速度（token/秒） | 延迟（TTFT） | 成本（美元/M token） | CrewAI最佳用途                 |
| :--------------------- | :--------------- | :----------- | :------------------ | :----------------------------- |
| **Llama 4 Scout**      | 2,600            | 0.33秒        | \$0.27              | 高容量处理Agent                 |
| **Gemini 2.5 Flash**   | 376              | 0.30秒        | \$0.26              | 实时响应Agent                   |
| **DeepSeek R1 Distill**| 383              | 可变         | \$0.04              | 成本优化的高速处理             |
| **Llama 3.3 70B**      | 2,500            | 0.52秒        | \$0.60              | 平衡速度和能力                 |
| **Nova Micro**         | 高               | 0.30秒        | \$0.04              | 简单快速的任务执行             |

这些模型优先考虑速度和效率，非常适合处理常规操作或需要快速响应的Agent。**专业提示**：将这些模型与像Groq这样的快速推理提供商配对可以实现更好的性能，特别是对于像Llama这样的开源模型。

**4、平衡性能**

**最适合通用团队**

| 模型                 | 总体得分 | 多功能性 | 成本（美元/M token） | CrewAI最佳用途           |
| :-------------------- | :------- | :------- | :------------------ | :----------------------- |
| **GPT-4.1**           | 53       | 优秀     | \$3.50              | 通用团队LLM              |
| **Claude 3.7 Sonnet** | 48       | 很好     | \$6.00              | 平衡推理和创意           |
| **Gemini 2.0 Flash**  | 48       | 好       | \$0.17              | 成本效益通用用途         |
| **Llama 4 Maverick**  | 51       | 好       | \$0.37              | 开源通用                 |
| **Qwen3 32B**         | 44       | 好       | \$1.23              | 预算友好的多功能性       |

这些模型在多个维度上提供良好性能，适合具有多样化任务需求的团队。

### 当前模型的选择框架

**1、高性能团队**

**当性能是优先事项时**：使用顶级模型如**o3**、**Gemini 2.5 Pro**或**Claude 4 Sonnet**作为管理器LLM和关键Agent。这些模型在复杂推理和协调方面表现出色，但成本较高。

**策略**：实施多模型方法，其中高级模型处理战略思维，而高效模型处理常规操作。

**2、预算敏感团队**

**当预算是主要约束时**：专注于像**DeepSeek R1**、**Llama 4 Scout**或**Gemini 2.0 Flash**这样的模型。这些以显著较低的成本提供强大性能。

**策略**：对大多数Agent使用成本效益模型，仅保留高级模型用于最重要的决策角色。

**3、专业化工作流**

**针对特定领域专业知识**：选择针对您主要用例优化的模型。**Claude 4**系列用于编码，**Gemini 2.5 Pro**用于研究，**Llama 405B**用于函数调用。

**策略**：根据团队主要功能选择模型，确保核心能力与模型优势一致。

**4、企业与隐私**

**对于数据敏感操作**：考虑可以本地部署同时保持竞争性能的开源模型，如**Llama 4**系列、**DeepSeek V3**或**Qwen3**。

**策略**：在私有基础设施上部署开源模型，接受潜在的性能权衡以换取数据控制。

### 模型选择的关键考虑因素

* **性能趋势**：当前格局显示推理专注模型（o3、Gemini 2.5 Pro）和平衡模型（Claude 4、GPT-4.1）之间的激烈竞争。像DeepSeek R1这样的专业模型提供出色的性价比。

* **速度与智能权衡**：像Llama 4 Scout这样的模型优先考虑速度（2,600 token/秒）同时保持合理的智能水平，而像o3这样的模型在成本和价格方面最大化推理能力。

* **开源可行性**：开源和专有模型之间的差距继续缩小，像Llama 4 Maverick和DeepSeek V3这样的模型以有吸引力的价格点提供竞争性能。快速推理提供商在开源模型方面尤其表现出色，通常提供比专有替代方案更好的速度成本比。

> **测试至关重要**：排行榜排名提供一般指导，但您的特定用例、提示风格和评估标准可能产生不同结果。在做出最终决定之前，始终用您的实际任务和数据测试候选模型。

### 实际实施策略

**1、从经过验证的模型开始**

从建立良好的模型开始，如**GPT-4.1**、**Claude 3.7 Sonnet**或**Gemini 2.0 Flash**，这些模型在多个维度上提供良好性能并具有广泛的实际验证。

**2、识别专业需求**

确定您的团队是否有特定要求（编码、推理、速度），可以从专业模型中受益，如**Claude 4 Sonnet**用于开发或**o3**用于复杂分析。对于速度关键的应用，考虑像**Groq**这样的快速推理提供商以及模型选择。

**3、实施多模型策略**

根据Agent角色为不同Agent使用不同模型。管理器和复杂任务使用高能力模型，常规操作使用高效模型。

**4、监控和优化**

跟踪与您用例相关的性能指标，并准备在新模型发布或价格变化时调整模型选择。